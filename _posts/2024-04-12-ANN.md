---
layout: post
title: ANN, The core of Deep Learning
tags: [ANN, CSE, Data Science]
feature-img: "assets/img/0.post/2024-04-12/header.png"
thumbnail: "assets/img/0.post/2024-04-12/header.png"
categories: CSE
---

&emsp;**인공신경망**( artificial neural network, **ANN**)은 인간의 두뇌에서 영감을 얻은 알고리즘이다. 가끔 역전파알고리즘(Backpropagation Algorithm)을 이용한 다층퍼셉트론(Multi Layer Perceptron, **MLP**)을 가르키는 경우도 있지만, 이는 잘못된 정보로, 인공신경망은 이에 국한되지 않는다.

![image](https://github.com/KoderWiki/koderwiki.github.io/assets/153072257/136be932-a3c7-4bb6-8e2a-b32a14db6b23)

&emsp;인공신경망은 수많은 노드들로 구성되어있다. 한개의 노드는 여러 함수로 이루어진 계산 단위(calculation unit)이다. 각 노드를 용도별로 분리한 단위를 '**층**(Layer)', 각 노드가 얼마나 많은 노드와 정보를 주고 받는지 보는 연결의 수를 '망(net)'이라고 한다.

&emsp;초기에는 잘 사용되지 않았다. 인공신경망은 **경사 하강법**(gradient descent)과 관련된 문제뿐만 아닌 하드웨어와 병렬 연산의 성능이 매우 낮을 때에 등장했기 때문이다. 초기에는 **서포트 벡터 머신**(Support Vector Machine, **SVM**)과 **나이브 베이지안 알고리즘**(Naive Bayesian Algorithm)등에 밀렸지만, 현대에서는 하드웨어 성능이 향상되어 많은 관심을 받고 있다.

&emsp;인공신경망은 인간의 개입없이 컴퓨터가 지능적으로 결정을 내리도록 도움을 주고, **비선형적**(non-linear)이고 **복잡한(complex) 입력데이터(input)와 출력데이터(output)간의 관계를 학습하고 모델링**할 수 있기에 중요하다.

## 구조

#### 활성화 함수(Activation Function)

**활성화 함수**(Activation Function)란 퍼셉트론(Perceptron)의 출력값을 결정하는 **비선형(non-linear)함수**다. 비선형인 이유는 활성화 함수가 가중합의 선형 결합을 비선형 모델로 만들기 때문이다. 활성화 함수는 각 퍼셉트론 내 계산의 마지막 단계에 배치되어 뉴런의 활성화 여부를 결정한다.

![image](https://github.com/KoderWiki/koderwiki.github.io/assets/153072257/282a341f-0eaf-475e-b128-c503d3791908)

#### 층의 구조 (Layer)

**입력 계층(Input Layer)**

외부에서의 정보는 입력 계층에서 인공 신경망으로 들어간다. 입력 노드는 데이터를 처리하여 분석, 분류후에 다음 계층으로 전달한다.

**은닉 계층(Hidden Layer)**

은닉 계층은 입력 계층 또는 다른 은닉 계층에게서 정보를 얻는다. 인공신경망에는 **여러 층의 은닉 계층**이 존재할 수 있다. 각 은닉계층은 이전 층의 출력(output)을 분석해서 처리후에 다음 계층으로 전달한다.

**출력 계층(Output Layer)**

출력 계층은 인공 신경망이 처리는 모든 데이터의 최종 결과값을 제공한다. 단일 또는 다중노드를 가질 수 있다. 예를 들어 이진분류(binary classification)문제가 있는 경우 출력 계층에는 하나의 출력 노드가 있고 결과는 1 또는 0이다. 하지만 다중 클래스 분류 문제가 있을 경우 출력 계층은 둘 이상의 출력 노드로 구성될 수 있다.

## 종류

신경망은 한 프로그램에 한개만 쓰이지 않는다. 예를 들어 **이미지 처리**(image processing)와 **자연어 처리**(national language processing, NLP)를 같이 할때 **CNN**과 **RNN**이 같이 쓰이는데, 이처럼 하나의 모델이 다른 유형의 데이터를 학습하는 것을 **멀티모달**(Multi Modal)이라고 한다.

### 퍼셉트론(Perceptron)

**퍼셉트론**(Perceptron)은 1957년에 제안된 초기 형태의 인공신경망으로 다수의 입력으로부터 하나의 결과를 내보내는 알고리즘이다. 퍼셉트론은 수학적(함수)로 뉴런을 모방하여 실제 뇌를 구성하는 뉴런의 동작과 유사하다. **입력층(수상돌기), 은닉층(핵), 출력층(축삭 말단)의 세층**으로 이루어져 있으며, 하나의 뉴런을 사용하여 학습 데이터를 가장 잘 설명하는 최적의 **패러미터**(parameter, 매개변수)를 찾는다.

![image](https://github.com/KoderWiki/koderwiki.github.io/assets/153072257/262558e7-4cd3-49da-9b7a-d5d20ec80d0a)

#### 단층 퍼셉트론(Single-Layer Perceptron)

입력층과 출력층만 있는 구조이다. 값을 보내는 단계와 값을 받아서 출력하는 두 단계로만 이루어지며, 이때 각 단계를 보통 층(layer)이라 부르고, 이 두개의 층을 입력층(input layer)과 출력층(output layer)이라고 한다.

![image](https://github.com/KoderWiki/koderwiki.github.io/assets/153072257/07c7e6ff-2a0b-410d-8de1-c89099748c06)

#### 다층 펴셉트론(Multi-Layer Perceptron, MLP)

본격적으로 **인공신경망**이라 불리는 단계다. 다층 퍼셉트론과 단층 퍼셉트론의 차이는 다층 퍼셉트론은 중간에 층을 더 추가했다는 점이다. 이런 입력층과 출력층 사이에 존재하는 층을 **은닉층**(Hidden Layer)이라고 한다.

![image](https://github.com/KoderWiki/koderwiki.github.io/assets/153072257/3b1ecfcd-01ed-4c89-93fd-cb3efd89d531)

다층 퍼셉트론중에 위와 같이 은닉층이 **2개 이상**인 신경망을 **심층 신경망**(Deep Neural Network, DNN)이라고 한다. 퍼셉트론이 제대로 된 정답을 출력할때 까지 기계가 가중치를 스스로 찾아내도록 자동화가 되어야 하는데, 이것이 머신러닝에서 말하는 **훈련**(training) 또는 **학습**(learning) 단계에 해당된다. 그리고 만약 학습을 시키는 인공신경망이 심층 신경망일 경우 이를 **심층학습**(Deep Learning, 딥러닝)이라고 한다.



## References

[AWS, What is a Neural Network?](https://aws.amazon.com/what-is/neural-network/?nc1=h_ls) <br>
[Perceptron](https://wikidocs.net/24958) <br>
















