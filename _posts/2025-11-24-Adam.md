---
date: 2025-11-24 17:45:59
layout: post
title: Adaptive Moment Estimation Optimizer
subtitle: 'Adam Optimizer'
description: >-
  Adam Optimizer와 타 최적화 알고리즘과의 비교
image: >-
  https://koderwiki.github.io/assets/img/0.post/linear/adam.gif
optimized_image: >-
  https://koderwiki.github.io/assets/img/0.post/linear/adam.gif
category: Optimization
tags:
    - Adam
    - Optimizer
  - Machine Learning
  - Deep Learning
  - Anomaly Detection
  - Data Science
  - blog
author: geonu.Ko
paginate: true
use_math : true
---

## Adaptive Moment Estimation

### Introduction

Adam(ADAptive Moment estimation)은 딥러닝에서 가장 널리 사용되는 최적화 알고리즘으로, Momentum의 안정적 방향성과 RMSProp의 adaptive learning rate를 결합한 방법론이다. <br>

Adam은 gradient의 1st moment(평균)과 2nd moment(variance)를 추정하고, parameter마다 서로 다른 학습률로 곱해준다. <br>

다른 최적화 알고리즘 (e.g., SGD, NAG, etc) 보다 빠르고 안정적이여서 딥러닝 모델에서 많이 쓰이고 있다.